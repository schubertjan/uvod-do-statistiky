# Pravděpodobnostní rozložení

Tuto kapitolu začneme videm.

![Matemateca (IME USP) / name of the photographer when stated, CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0>, via Wikimedia Commons](https://upload.wikimedia.org/wikipedia/commons/d/dc/Galton_box.webm){width="640" height="360"}

Proč kuličky v tomto videu skončí v určitém množství v určitém sloupci? A proč skončí podobné množství kuliček v každém sloupci, pokud bychom kuličky pustili znova? Jak by se počet kuliček ve soupcích lišil?

Pokud si z této knihy máte odnést jednu kapitolu, pak by to měla být tako :). Jak jsme zmínili v úvodu knihy, většina proměnných okolo nás se chová náhodně. To znamená, že může nabývat náhodných hodnot podle nějakého klíče (procesu). Náhodnost může vycházet z faktu, že měříme jenom nějakou část populace (např. výběrové šetření), z fyzikálních vlastností (např. váha součástky vyrobená v továrně nebude vždy stejná) nebo z chyby měření (např. teploměr nezměří stejnou teplotu vždy stejně, ale hodnoty měření budou kolísat okolo nějakého čísla). Pravděpodobnostní rozložení nám pomáhají kvantifikovat a predikovat míru nahodilosti. Typ pravděpodobnostního rozložení, který na popsání náhodnosti uplatníme vychází z našeho porumění vlastnostní rozložení a jeho vhodnosti na daný problém. A vlastnosti pravděpodobnostních rozložení je to, co si v této kapitole ukážeme.

Na začátku jsme řekli, že budeme používat statistické modely a že tyto modely nejsou přesným vyjádřením reality, ale mohou být užitečným popsáním reality. V této kapitole začneme modely používat.

## Pravděpodobnostní rozložení jako jazyk statistiky

V této kapitole si ukážeme spoustu nových značení, která se stanou našim jazykem, kterým budeme ve statistice komunikovat. Budeme je používat k tomu, abychom popsali očekávané chování náhodné proměnné. Každé rozložení má svoje **parametry**, pomocí kterým ho můžeme popsat. Každé rozložení má taky svoje **míry centrální tendence** (**očekávanou hodnotu**) a svoje **míry rozptýlenosti**. To, kolik hodnot náhodné proměnné nabývá určitých hodnot popisuje **hustota pravděpodobnosti**. V angličtině se u spojitých proměnných (která nabývají reálných čísel) vyjadřuje hustota pravděpodobnosti jako **probability density function** (PMF). U diskrétních proměnných (nabývají celých čísel) se hustota pravděpodobnosti nazývá **probability density function** (PMF). Integrál hustoty pravděpodobnosti je vždy rovný nule. To tedy znamá, že kdybychom sečetli všechny hodnoty hustoty pravděpodobnosti (pro spojité proměnné integrovali), tak by se výsledek rovnal jedné. To plyne z toho, že pravděpodobnost jevu nemůže být vyšší než jedna. Nakonec ještě trocha **terminologie**, které budeme používat. Náhodnou proměnnou budeme označovat jako $x_i$. Budeme používat malá písmena, pokud výsledkem procesu bude vektor a velká písmena, pokud výsledkem bude matice. $i$ označuje jednotlivá pozorování. Teda první hodnota náhodné proměnné, by se označovala jako $x_1$. $n$ označuje zpravidla počet pozorování proměnné.

## Binomické

Vraťme se k videu ze začátku kapitoly. Tomuto přístroji se říká Galton Box. Míčky jsou puštěny do přístroje z jednoho stejného bodu a procházejí několika vrstvami (ve videu 10 vrstvami). V každé vrstvě míček narazí na bod, který ho může poslat na levou nebo na pravou stranu (zhruba se stejnou pravděpodobností 0.5). To, na jakou stranu se míček vydá je určeno náhodou. Míčky potom spadnou do jednoho ze sloupců (ve videu 13 sloupců). Kdybysme nechali všechny míčky spadnout, posbírali je a znovu spustili, tak skoro stejné množství míčků skončí v každém sloupci. Jak je možné, že když spustíme tisíce míčků, každý se může 10x odrazit nalevo nebo napravo, tak výsledný počet míčků v každém sloupci je skoro stejný? Příčinou je pravděpodovnoství rozložení. 

Prvním rozložením, které si ukážeme je binomické rozložení. Jevy mohou být generovany procesem, který vede k binomickému rozložení, pokud máme pokus, jehož výsledkem je **úspěch nebo neúspěch**, pokusy jsou **nezávislé** a mají **konstantní pravděpodobnost** úspěchu $p$ (konstantní pro všechny pokusy). Obecně platí, že proměnná $x_i$ pochází z binomického rozložení, kde $$x_i \sim B(n, p)$$ a kde $n$ značí počet pokusů a $p$ pravděpodobnost úspěchu. Proměnná $x_i$ je potom **diskrétní**. Pojďme si ukázat, jak se binomické rozložení vztahuje ke Galtonově boxu. Každý míček prochází 10 pokusy, kde výsledek může být buď úspěch (řekněme, že míček spadne napravo) nebo neúspěch (řeknemě, že míček spadne nalevo). Výsledkem je potom zařazení do jednoho ze 13 sloupců. V extrému může náš proces skončit tak, že všechny míčky budou nalevo nebo že všechny míčky budou napravo. Míčky jsou na sobě relativně nezávislé a všechny mají při každém pokusu relativně konstatní pravděpodobnost. Opět je nutné si uvědomit, že náš model dat (binomické rozložení) není přesnou reprezentací procesu, který se snažíme popsat. Míčky nejsou ve skutečnosti kompletně nezávislé, mohou do sebe narazit a tím se ovlivnit. Protože ale prochazí zhruba 10 pokusy (i když to se může lišit, některé míčky se mohou odrazit po nárazu znovu nahoru), bereme proces jako dostatečně náhodný a nezávislý. Důležité je, jestli jsou předpoklady našeho modelu splněny dostatečně na to, aby jeho matematické vyjádření bylo validní pro reálný process, který se snažíme popsat.

Pojďme si nyní ukázat, jak se Galtonův box dá připodobnit binomickým rozložením. Náhodný process z binomického rozložení můžeme generovat pomocí funkce `rbinom`. Ta jako argumenty předpokládá `n` počet pozorování, která chceme generovat, `size` počet pokusů (způsobů, jak může proces skončit) a `p` pravděpodobnost úspěchu. Budeme uvaživat, že spustíme 10 000 míčků, tedy $$x_i \sim B(10000, 0.5)$$

```{r, fig.cap='Simulace Galtonova boxu s 13 sloupci'}
set.seed(4)
# pocet micku
n <- 10000
# pravdepodobnost uspechu (napravo)
p <- 0.5
# 0 by znamenalo všechny míčky nalevo, 12 všechny míčky napravo,
# celkem 13 možností, jak mohou míčku skončit
s <- 12

vysledek <- rbinom(n = n , size = s, prob = p)
cetnost <- table(vysledek)
plot(cetnost,
     xlab = "x",
     ylab = "Četnost",
     main = paste0("Galtonův box s ", n, " míčky"),
     col = "#1f77b4",
     type= "h", lwd = 15, 
     xlim = c(0, 12))
# vzdy ukazat vsechny moznosti i kdyz tam nejsou zadne micky
axis(1, 1:13, 1:13)
```

**Očekávanou hodnotu** proměnné pocházející z binomické proměnné můžeme vypočítat jako $$E(x_i) = np$$ **variabilitu** jako $$Var(x_i) = npq$$ a **směrodatbou odchylku** jako $$Sd(x_i) = \sqrt{Var(X_i)}$$V našem případě, kdy máme `r n` míčků je tedy očekávaná hodnota `r n*p` a směrodatná odchylka `r n*p*(1-p)`.

A ještě ukázka, že počet míčků v každém sloupci je zhruba stejný, pokud bychom je pustili znova, řekněme 11x.

```{r, animation.hook='gifski', fig.cap='Opakované spuštění míčků v Galtonově boxu'}
N <- 11
for(i in 1:N) {
  vysledek <- rbinom(n = n , size = s, prob = p)
  micek <- vysledek[1]
  cetnosti <- table(vysledek)
  # pouzijeme funkci plot, abychom mohli pridat micek
  plot(cetnosti,
       xlab = "x",
       ylab = "Četnost",
       main = paste0("Galtonův box s ", n, " míčky; pokus #", i),
       col = "#1f77b4",
       lwd = 15,
       ylim = c(0, 2500),
       xlim = c(0, 12))
  # vzdy ukazat vsechny moznosti i kdyz tam nejsou zadne micky
  axis(1, 1:13, 1:13)
  points(x = micek, y = 2, pch = 19, col = "red")
}
```

Jak jsme zmínili v \@ref(pravděpodobnostní-rozložení-jako-jazyk-statistiky) frekvenci hodnot diskrétní náhodné proměnné můžeme popsat matematicky pomocí hustoty pravděpodobnosti (PMF). U binomického rozložení můžeme PMF vypočítat jako $$PMF(x_i) = \binom{n}{k}p^kq^{n-k}$$ kde $k$ je počet úspěšných pokusů a $q=1-p$. V praxi můžeme využít funkce `dbinom`, která PMF vypočítá. Tato funkce argument `x` kam dosadíme hodnoty proměnné $x_i$, pro které chceme PMF vypočítat. Argumenty `size` a `prob` jsou stejné jako u `rbinom`. Protože PMF je vypočítáno deterministicky (není tam žádná náhoda jako u generování náhodných čísel nahoře, čísla pouze dosadíme do vzorce), bude jeho výpočet stejný pokaždé, když zadáme stejné argumenty funkce.

```{r, fig.cap='PMF pro Galtonův box s 13 sloupci'}
# muze padnou minimalne 0 (uplne nalevo) a maximalne 12 (uplne napravo)
x <- 0:12
s <- 12
p <- 0.5

pmf <- dbinom(x = x, size = s, prob = p)
plot(x, pmf, 
     xlab = "x",
     ylab = "PMF",
     type = "h", # jedna se o diskretni promennou
     lwd = 15,
     main = paste0("Galtonův box"),
     col = "#1f77b4")
# vzdy ukazat vsechny moznosti i kdyz tam nejsou zadne micky
 axis(1, 1:13, 1:13)
```

Protože hodnoty $x_i$ mohou nabývat pouze celých čísel, je PMF vyjádřením pravděpodobnosti toho, že náhodná proměnná $x_i$ nabyde nějaké hodnoty. Nejpravděpodobněji skončí míček ve sloupci `r x[which.max(pmf)]` s pravděpodobností `r which.max(pmf)`, nebo matematickým zápisem $P(x_i=$ `r x[which.max(pmf)]` $)=$ `r max(pmf)`. Pravěpodobnost, že míček skončí v 4 sloupci zleva je $P(x_i = 2)$=`r pmf[x==3]`. To, že dokážeme predikovat, kolik míčků skončí v jakém sloupci, ještě neznamená, že víme, kde skončí jeden konkrétní míček. V animaci nahoře si všimněte červené tečky. Ta reprezentuje první míček, který jsme vhodili. Jak je vidět míček cestuje mezi sloupci. To s jakou pravděpobností skončí v daném sloupci nám říká právě PMF.


Stejně tak můžeme spočítat pravděpodobnost, že skončí v 7 sloupci a více napravo, tedy $P(x \ge 7)$=`r sum(pmf[x>=7])`. Tomuto typu úlohy, kdy nás zajímá, zda náhodná proměnná $x_i$ bude mít hodnotu menší/větší než nějaká hodnota $q$, říkáme **kumulativní pravděpodobnosti** (anglicky cumulative distribution function CDF). Matematicky bychom tento typ úlohy označili jako $P(x_i < q)$ pokud by nás zajímala pravděpodobnost, že náhodné proměnné $x_i$ bude menší než nějaká hodnota $q$ a $P(x_i > q)$, pokud by nás zajímala pravděpodobnost, že hodnota  náhodné proměnné $x_i$ bude větší než nějaká hodnota $q$. `R` můžeme na výpočet CDF u binomického rozložení použít funkci `pbinom`. Jako argumenty očekává tato funkce `q` hodnota náhodné proměnné vůči které porovnáváme porovnáváme, `size` a `prob` mají stejný význam jako u funkcí nahoře a argument `lower.tail` vyjadřující, zda chceme zjistit pravděpodobnost, že $x_i$ bude menší nebo větší a rovno než $q$. Pokud má argument `lower.tail` hodnotu `TRUE`, pak počítáme $P(x_i \le q)$, pokud má hodnotu `FALSE`, pak počítáme $P(x_i > q)$. Pojďme si ukázat různé výpočty a jejich zobrazení na grafu. Začneme $P(x > 7)$.
```{r, fig.cap='Ukázka výpočtu P(x > 7) pomocí PMF'}
# P(x > 7)
p_x7 <- pbinom(q = 7, size = s, prob = p, lower.tail = FALSE)
plot(x, pmf, 
     xlab = "x",
     ylab = "PMF",
     type = "h", # jedna se o diskretni promennou
     lwd = 15,
     main = paste0("P(x > 7)=", round(p_x7, 2)),
     col = "grey")
axis(1, 1:13, 1:13)
# zobrazime graficky P(x > 7)  
lines(x[x>7], pmf[x>7], 
      type = "h", # jedna se o diskretni promennou, 
      lwd = 15,
      col = "#1f77b4")
```

Dále si ukažme jak vypočítat $P(x \le 5)$. 
```{r, fig.cap='Ukázka výpočtu P(x <= 5) pomocí PMF'}
# P(x <= 5)
p_x5 <- pbinom(q = 5, size = s, prob = p, lower.tail = TRUE)
plot(x, pmf, 
     xlab = "x",
     ylab = "PMF",
     type = "h", # jedna se o diskretni promennou
     lwd = 15,
     main = paste0("P(x <= 5)=", round(p_x5, 2)),
     col = "grey")
axis(1, 1:13, 1:13)
# zobrazime graficky P(x > 7)  
lines(x[x<=5], pmf[x<=5], 
      type = "h", # jedna se o diskretni promennou, 
      lwd = 15,
      col = "#1f77b4")
```

A nakonec $P(x_i \ge 6)$.
```{r, fig.cap='Ukázka výpočtu P(x >= 6) pomocí PMF'}
# P(x >= 6)
# pouzijeme FALSE na vypocet upper tail a za 1 dosadime 5, protoze...
# ...lower.tail = FALSE pocita P(x_i > q)
p_x6 <- pbinom(q = 5, size = s, prob = p, lower.tail = FALSE)
plot(x, pmf, 
     xlab = "x",
     ylab = "PMF",
     type = "h", # jedna se o diskretni promennou
     lwd = 15,
     main = paste0("P(x >= 6)=", round(p_x6, 2)),
     col = "grey")
axis(1, 1:13, 1:13)
# zobrazime graficky P(x > 7)  
lines(x[x>=6], pmf[x>=6], 
      type = "h", # jedna se o diskretni promennou, 
      lwd = 15,
      col = "#1f77b4")
```


## Normální
Normální rozložení popisuje náhodný proces **spojitých** proměnných. Za určitých podmínek (velký výběr a $p$ neblížící se 0 nebo 1) se binomické rozdělení bude podobat normálnímu. Normální rozložení popisuje proces, kterým jsou generované náhodné spojité proměnné, které nejsou ohraničené zleva ani zprava. Protože mnoho fyzikálních jevů je spojitých^[Např. teplota, hmotnost, výška. Naše schonost tyto jevy měřit je ale často diskrétní, hmotnost můžeme měřit na mg apod. Protože jsou ale jednotky míry často malé, bereme je jako spojitou proměnnou.] a nejsou ohraničeny^[Teoreticky jsou ohraničené, ale prakticky se v přírodě extrémy často nevyskutují. Například teplota neklesá k absolutní nule. Váha zvířat je zpravidla větší než 0 mg apod.], normální rozložení se často vyskuteje v přírodě. Normální rozložení má dva parametry, které určují jeho tvar, průměr $\mu$ a směrodatnou odchylku $\sigma$. Náhodná proměnná $x_i$ pocházející z normálního rozložení se zapíše jako $$x_i \sim N(\mu, \sigma)$$Parameter $\mu$ ovlivňuje polohu rozložení a parameter $\sigma$ jeho roztaženost nalevo a napravo od $\mu$. Protože náhodná proměnná $x_i$ je spojitá, nabývá reálných čísel, může mít  nekonečně mnoho hodnot. To představuje problém, pokud chceme vypočítat hustotu pravděpodobnosti (PDF). Aby byly zachovány vlastnosti pravděpodobnosti ($p \in [0, 1]$), je integrál PDF rovný jedné To ale znamená, že hodnota PDF už nevyjadřuje pravděpodobnost nějakého jevu. V angličtině se proto používá pojem density (odtud probability density function PDF). Vzorec pro PDF je
$$PDF(x_i) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{1}{2} (\frac{x - \mu}{\sigma})^2}$$
v `R` můžeme pro výpočet PDF normálného rozložení použít funkci `dnorm`, které má argumenty `x` hodnoty náhodné proměnné $x_i$, pro které chceme PDF vypočítat, `mean` průměr a `sd` standardní odchylku. Pojďme si ukázat, jak by vypadala PDF pro tyto náhodné proměnné:
$$x_i \sim N(0, 1)$$
$$y_i \sim N(3, 2)$$
$$z_i \sim N(-2, 3)$$



```{r, fig.cap='Ukázka vlivu průměru a směrodatné odchylky na tvar normálního rozložení'}
# definujeme si parametry
mu <- c(0, 3, -2)
s <- c(1, 2, 3)
# definuje hodnoty nahodne promenne, pro kterou budeme chtit vypocitat pdf
x <- seq(-12, 12, length.out = 1000)

# vypocitame pdf
pdf_x <- dnorm(x = x, mean = mu[1], sd = s[1])
pdf_y <- dnorm(x = x, mean = mu[2], sd = s[2])
pdf_z <- dnorm(x = x, mean = mu[3], sd = s[3])

# zobrazime
plot(x, pdf_x, 
     col = "#1f77b4", 
     lwd = 2, type = "l", 
     xlab = "", ylab = "PDF",
     xlim = c(-12, 12))
lines(x, pdf_y, col = "black", lwd = 2)
lines(x, pdf_z, col = "orange", lwd = 2)
legend("topright", 
       legend = c("x ~ N(0, 1)", "y ~ N(3, 2)", "z ~ N(-2, 3)"), 
       lwd = rep(2, 3), 
       col = c("#1f77b4", "black", "orange"), 
       cex = 0.7)
```

Normální rozložení je symetrické. To znamená, že se nachází stejně hodnot nalevo a napravo od průměru. Podle hodnoty směrodatné odchylky dokážeme určit kolik případů bychom a jak daleko bychom očekávali, že budou ležet od průměru. Následující obrázek ukazuje, že zhruba 68% hodnot náhodné proměnné bude ležet +/- jednu směrodatnou odchylku od průměru a zhruba 95% hodnot bude ležet +/- dvě směrodatnou odchylku od průměru a 99% hodnot +/- tři směrodatné odchylky od průměru.

![M. W. Toews, CC BY 2.5 <https://creativecommons.org/licenses/by/2.5>, via Wikimedia Commons](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/700px-Standard_deviation_diagram.svg.png)

**Očekávanou hodnotou** normálního rozložení je průměr, tedy $E(x_i)=\mu$ a **variabilitou** je $Var(x_i) = \sigma^2$, tedy směrodatnou odchylkou je $\sigma = \sqrt{\sigma^2}$.

Pojďme se nyní podívat, co se stane s funkcí normálního rozložení, pokud k náhodné proměnné $x_i$ **přičteme skalár**. Podíváme se na následující proměnnou $$h_i \sim N(170, 20)$$tedy proměnnou, která pochází z normálního rozložení s průměrem 170 a směrodatnou odchylkou 20. K této náhodné proměnné přičteme +10, tedy $h'_i = h_i + 60$ a spočítáme průměr a směrodatnou odchylku. Ke generování náhodných čísel z normálního rozložení použijeme funkci `rnorm`, který má argumenty `n` počet pozorování, které chceme generovat, `mean` průměr rozložení, z kterého chceme generovat a `sd` směrodatnou odchylku rozložení, z kterého chceme generovat.
```{r, fig.height=7, fig.cap='Efekt přičtení skalaru na rozložení proměnné'}
n <- 1e5
h <- rnorm(n, mean = 170, sd = 20)
h. <- h + 20
par(mfrow = c(2, 1))

hist(h,
     col = "#1f77b4", 
     xlab = "", ylab = "Četnost",
     breaks = 15,
     xlim = c(100, 260),
     main = paste0("Průměr=", round(mean(h), 0), 
                   ",sd=", round(sd(h), 0)))
hist(h.,
     col = "grey", 
     xlab = "", ylab = "Četnost",
     breaks = 15,
     xlim = c(100, 260),
     main = paste0("Průměr=", round(mean(h.), 0), 
                   ",sd=", round(sd(h.), 0)))
```
Jak je vidět přičtení (nebo odečtění) má vliv pouze na průměr a tedy polohu rozložení. V případě přičtení čísla $a$ se celé rozložení posune doprava o $a$, v případě odečtení se potom posune celé rozložení doleva. Přičtení/odečtení nemá vliv na směrodatnou odchylku, tedy na šířku rozložení od průměru. Tento fakt můžeme zapsat jako $$h'_i \sim N(\mu_h \pm a, \sigma_h)$$

Dále se podíváme na to, co se stane s rozložením náhodné proměnné $$h_i \sim N(170, 20)$$pokud ji **vynásobíme skalarem**. Náhodnou proměnnou $h_i$ vynásobíme číslem 0.5, tedy $h'_i = h_i * 0.5$ a spočítáme průměr a směrodatnou odchylku. Jak je vidět vynásobení (nebo jako v našem případě dělení) má vliv na průměr i směrodatnou odchylku. Oba parametry normálního rozložení se změní o faktor, kterým původní náhodnou proměnnou násobíme, tedy v našem případě se zmenší o polovinu. Tento fakt můžeme zapsat jako $$h'_i \sim N(\mu_h * a, \sigma_h * a)$$

```{r, fig.height=7, fig.cap='Efekt vynásobení skalarem na rozložení proměnné'}
h. <- h * 0.5
par(mfrow = c(2, 1))

hist(h,
     col = "#1f77b4", 
     xlab = "", ylab = "Četnost",
     breaks = 15,
     xlim = c(50, 240),
     main = paste0("Průměr=", round(mean(h), 0), 
                   ",sd=", round(sd(h), 0)))
hist(h.,
     col = "grey", 
     xlab = "", ylab = "Četnost",
     breaks = 15,
     xlim = c(50, 240),
     main = paste0("Průměr=", round(mean(h.), 0), 
                   ",sd=", round(sd(h.), 0)))
```

Dále se podíváme, co se stane s průměrem a směrodatnou odchylkou, pokud k sobě **přičteme dvě náhodné proměnné pocházející z normálního rozložení**. Budeme mít dvě náhodné proměnné, které pocházejí z normálního rozložení 
$$h_i \sim N(170, 20)$$a$$l_i \sim N(50, 10)$$Budeme sledovat, co se stane s průměrem a směrodatnou odchylkou nové proměnné $k_i$, která vznikne sečtením $h_i$ a $l_i$, tedy $k_i = h_i + l_i$. Jak vidíme na grafu dole, nová proměnná má průměr rovný $\mu_k = \mu_h + \mu_l$ a $\sigma_k = \sqrt{\sigma_h^2 + \sigma_l^2}$, tedy $$k_i \sim N(\mu_h + \mu_l, \sqrt{\sigma_h^2 + \sigma_l^2})$$

```{r, fig.height=7, fig.cap='Efekt přičtení dvou normálně rozložených náhodných proměnných na rozložení nové proměnné'}
l <- rnorm(n = n , mean = 50, sd = 10)
k <- h + l
par(mfrow = c(3, 1))

hist(h,
     col = "#1f77b4", 
     xlab = "h", ylab = "Četnost",
     breaks = 10,
     xlim = c(20, 330),
     main = paste0("Průměr=", round(mean(h), 0), 
                   ",sd=", round(sd(h), 0)))
hist(l,
     col = "grey", 
     xlab = "l", ylab = "Četnost",
     breaks = 10,
     xlim = c(20, 330),
     main = paste0("Průměr=", round(mean(l), 0), 
                   ",sd=", round(sd(l), 0)))

hist(k,
     col = "azure4", 
     xlab = "k", ylab = "Četnost",
     breaks = 10,
     xlim = c(20, 330),
     main = paste0("Průměr=", round(mean(k), 0), 
                   ",sd=", round(sd(k), 0)))
```

Jako poslední výpočetní operaci náhodných proměnných pocházejících z normálního rozložení si ukážeme, co se stane pokud od sebe **odečteme dvě náhodné proměnné pocházející z normálního rozložení**. Budeme opět uvažovat náhodné proměnné $$h_i \sim N(170, 20)$$a$$l_i \sim N(50, 10)$$a budeme počítat $k_i = h_i - l_i$. Jak je vidět z grafu dole, nový průměr má hodnotu $\mu_k = \mu_h - \mu_l$, ale směrodatná odchylka je stále rovna $\sigma_k = \sqrt{\sigma_h^2 + \sigma_l^2}$. To je důležitý poznatek o odečtu dvou normálně rozložených proměnných. Směrodatná odchylka nové proměnné tedy bude vždy součtem směrodatných odchylek původních proměnných. Tento jev se dá zapsat jako $$k_i \sim N(\mu_h - \mu_l, \sqrt{\sigma_h^2 + \sigma_l^2})$$

```{r, fig.height=7, fig.cap='Efekt odečtení dvou normálně rozložených náhodných proměnných na rozložení nové proměnné'}
k <- h  - l
par(mfrow = c(3, 1))

hist(h,
     col = "#1f77b4", 
     xlab = "h", ylab = "Četnost",
     breaks = 10,
     xlim = c(20, 330),
     main = paste0("Průměr=", round(mean(h), 0), 
                   ",sd=", round(sd(h), 0)))
hist(l,
     col = "grey", 
     xlab = "l", ylab = "Četnost",
     breaks = 10,
     xlim = c(20, 330),
     main = paste0("Průměr=", round(mean(l), 0), 
                   ",sd=", round(sd(l), 0)))

hist(k,
     col = "azure4", 
     xlab = "k", ylab = "Četnost",
     breaks = 10,
     xlim = c(20, 330),
     main = paste0("Průměr=", round(mean(k), 0), 
                   ",sd=", round(sd(k), 0)))
```

Kumulativní rozložení




## T

location

## Uniformní

Model Země

```{r, fig.cap='Model Země', fig.align='center', echo=FALSE, message=FALSE, warning=FALSE}
library(plotly)

df <- read.csv("https://raw.githubusercontent.com/plotly/datasets/master/globe_contours.csv")
df$id <- seq_len(nrow(df))

library(tidyr)
d <- df %>%
  gather(key, value, -id) %>%
  separate(key, c("l", "line"), "\\.") %>%
  spread(l, value)

geo <- list(
  showland = TRUE,
  showlakes = TRUE,
  showcountries = TRUE,
  showocean = TRUE,
  countrywidth = 0.5,
  landcolor = "rgb(230, 145, 56)",
  lakecolor = "rgb(0, 255, 255)",
  oceancolor = "rgb(0, 255, 255)",
  projection = list(
    type = "orthographic",
    rotation = list(
      lon = -100,
      lat = 40,
      roll = 0
    )
  ),
  lonaxis = list(
    showgrid = TRUE,
    gridcolor = toRGB("gray40"),
    gridwidth = 0.5
  ),
  lataxis = list(
    showgrid = TRUE,
    gridcolor = toRGB("gray40"),
    gridwidth = 0.5
  )
)


# sliders
lon_range <- data.frame(seq(-180, 180, 10))
lat_range <- data.frame(seq(-90, 90, 10))
colnames(lon_range) <- "x"
colnames(lat_range) <- "x"

all_lat <- list()
for (i in 1:length(lat_range[, ])) {
  all_lat[[i]] <- list(
    method = "relayout",
    args = list(list(geo.projection.rotation.lat = lat_range$x[i])),
    label = lat_range$x[i]
  )
}

all_lon <- list()
for (i in 1:length(lon_range[, ])) {
  all_lon[[i]] <- list(
    method = "relayout",
    args = list(list(geo.projection.rotation.lon = lon_range$x[i])),
    label = lon_range$x[i]
  )
}


# original d3-globe with contours
fig <- plot_geo(d)
fig <- fig %>% layout(
  showlegend = FALSE, geo = geo
)

# plot with custom events
fig <- fig
fig <- fig %>% layout(sliders = list(
  list(
    active = (length(lon_range[, ]) - 1) / 2,
    currentvalue = list(prefix = "Longitude: "),
    pad = list(t = 20),
    steps = all_lon
  ),
  list(
    active = (length(lat_range[, ]) - 1) / 2,
    currentvalue = list(prefix = "Latitude: "),
    pad = list(t = 100),
    steps = all_lat
  )
))

fig
```

## Poisson

dispersed poisson

## Chi-kvadrát

## Shrnutí 

Pomocí této aplikace si můžete vyzkoušet, jak různé parametry ovlivňují tvar rozložení nebo vypočítat pravděpodobnost, že náhodná proměnná $x_i$ nabyde určitých hodnot $a$.
```{r, echo=FALSE}
knitr::include_app("https://gallery.shinyapps.io/dist_calc/")
```

Zdroj: https://github.com/ShinyEd/intro-stats/tree/master/dist_calc

## Věrohodnost

```{r, message=FALSE, warning=FALSE}
library(leaflet)
```

```{r}
v2_location <- read.csv("../dats/v2_location.csv")
v2_location <- v2_location[complete.cases(v2_location), ]
v2_location$label <- paste(paste(v2_location$landing_site, v2_location$date, sep = ", "))

v2_location$lat <- v2_location$lat + rnorm(nrow(v2_location), 0 , 0.01)
v2_location$lon <- v2_location$lon + rnorm(nrow(v2_location), 0 , 0.05)
# greater london area
mu <- c(51.5072178, -0.1275862)
lon <- c(-0.492267, 0.362430)
lat <- c(51.274614, 51.73982)

# index
i <- (v2_location$lat >= lat[1] & v2_location$lat <= lat[2]) & (
  v2_location$lon >= lon[1] & v2_location$lon <= lon[2]
)

v2_london <- v2_location[i, ]

leaflet(data = v2_london) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addCircleMarkers(
    lng = ~lon,
    lat = ~lat, color = "#000000",
    opacity = 0.2,
    fillOpacity = 0.2,
    fillColor = "#000000",
    radius = 2.5,
    stroke = FALSE,
    label = ~label
  )
```
```{r}
# simulujeme nemoznost mireni
n <- nrow(v2_london)
v2_uni <- data.frame(lon = runif(n = n, 
                                 min = lon[1], 
                                 max = lon[2]),
                     lat = runif(n = n, 
                                 min = lat[1], 
                                 max = lat[2]))

v2_norm <- data.frame(lon = rnorm(n = n, 
                                  mean = mean(v2_london$lon), 
                                  sd = sd(v2_london$lon)),
                     lat = rnorm(n = n, 
                                 mean = mean(v2_london$lat), 
                                 sd = sd(v2_london$lat)))

fig <- leaflet(data = v2_london) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addCircleMarkers(
    lng = ~lon,
    lat = ~lat, color = "#000000",
    opacity = 0.2,
    fillOpacity = 0.2,
    fillColor = "#000000",
    radius = 2.5,
    stroke = FALSE,
    label = ~label
  )

fig <- addCircleMarkers(map = fig,
    lng = v2_norm$lon,
    lat = v2_norm$lat, color = "#1f77b4",
    opacity = 0.2,
    fillOpacity = 0.2,
    fillColor = "",
    radius = 2.5,
    stroke = FALSE,
    label = "Uniform"
  )
fig
```
