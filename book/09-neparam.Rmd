# Neparametrické testy

Neparametrické testy používáme, pokud jsou předopklady některých parametrických testů porušeny, nejčastěji normalita rozdělení nebo předpoklady o spojitosti proměnné. 

## Znaménkový test

Nejjednodušším testem je znaménkový test. Tento test používáme, když chceme porovnat medián proměnné k populační hodnotě. Jde tedy o ekvivalement jednovýběrového t-testu (viz \@ref(stats-test-single). Pojďme si znaménkový test ukázat na následujícím příkladu. Na filmové databázi IMDb mohou registrovaní uživatelé a uživatelky hodnotit filmy na škále od 1 do 10. Víte, že daný film na této databázi hodnotilo více než půl milionu uživatelů. Správce databáze vám při pracovním pohovoru na pozici datového analytika náhodně vygeneruje 14 hodnocení tohoto filmu: 
$x = [3, 7, 4, 10, 1, 6, 9, 8, 3, 6, 7, 5, 9, 8]$. Vedoucí analytického týmu databáze IMDb vám při pracovním pohovoru stanoví následující úlohu: Jaká je pravděpodobnost, že se jedná o zcela výjimečný film, který dostal od poloviny hodnotících uživatelů databáze známky 9 nebo 10 (tedy medián všech hodnocení je 9 nebo větší)? Graf \@ref(fig:znam-data) ukazuje hodnocení od nejmenší po největší hodnotu. Horizontální přímka vyjadřuje teoretickou hodnotu 9.

```{r znam-data, fig.cap='Sloupcový graf 14 hodnocení filmů'}
X <- c(3, 7, 4, 10, 1, 6, 9, 8, 3, 6, 7, 5, 9, 8)
k <-length(X)

plot(sort(X), 
     col = "#1f77b4", 
     xlab = "Pořadí",
     ylab = "Hodnocení",
     type = "h", lwd = 15)
abline(h = 9)
```

V tomto případě tedy testujeme, zda $H_0: \eta \le 8$, $H_1: \eta > 8$ (tedy 9 a více). Začněme tím, že se podíváme, kolik hodnot je vyšších, než testovaná hodnota $8$. Znaménko `"-"` značí hodnotu menší než 8 a znaménko `"+"` hodnotu větší než 8.

```{r}
h0 <- 8
znamenka <- X>h0

znamenka_table <- ifelse(znamenka, "+", "-")
names(znamenka_table) <- X
znamenka_table
```

Pokud by populační hodnota byla rovna $\eta=8$, z 14 hodnot bychom očekávali 7 vyšších než $\eta=8$ a 7 menších než $\eta=8$. Jedná se tedy vlastně o příklad binomického rozložení (\@ref(binom-dist)) s $k=14$ pokusy a pravděpodobností úspěchu $p=0.5$, tedy $B(14, 0.5)$. V našem případě je celkem `r sum(znamenka)` vyšších než testovaná hodnota 8. 

```{r znam-chart, fig.cap="Distribuce pozorování větších než teoretická hodnota za předpokladu H0. příklad jednosměrného testu."}
x <- 0:14
p <- 0.5
plusova_znamenka <- sum(znamenka)
pmf <- dbinom(x, size = k, prob = p)
p_hodnota <- sum(pmf[x>=plusova_znamenka])


plot(x, pmf,
     xlab = "x",
     ylab = "PMF",
     col = "grey",
     type = "h", lwd = 15,
     xlim = c(0, k),
     main = paste0("p=", round(p_hodnota, 2))
     )
lines(x[x>=plusova_znamenka], pmf[x>=plusova_znamenka], col = "#1f77b4", type = "h", lwd = 15)
axis(1, 0:k, 0:k)
```

Graf \@ref(fig:znam-chart) ukazuje rozdělení počtu hodnot větších než teoretická hodnota 8, pokud by v populaci platila $H_0$. V našem případě jsme měli `r sum(znamenka)` hodnoty větší než teoretická hodnota 8. Pokud platí $H_0$, pak je pravděpodobnost, že bychom z `r k` pozorování viděli `r plusova_znamenka` nebo více větších hodnot než $H_0$ je `r round(p_hodnota, 2)`. Tedy nemůžeme zamítnout $H_0: \eta \le 8$ ve prospěch $H_1$. Nelze tedy říci, že by byl medián hodnocení větší nebo roven 9.

Dále na stejných datech formulujeme hypotézu, že medián všech hodnocení tohoto filmu se nerovná 5. Formulujte odpovídající nulovou a alternativní hypotézu. Tedy $H_0: \eta = 5$, $H_1: \eta \ne 5$. Opět spočítáme počet případů, kdy je hodnocení vyšší než teoretická hodnota.  

```{r}
h0 <- 5
znamenka <- X>h0

znamenka_table <- ifelse(znamenka, "+", "-")
names(znamenka_table) <- X
znamenka_table
```

Pokud by populační hodnota byla rovna 5, pak bychom opět v našem výběru čekali 7 pozorování menších, než teoretická hodnota a 7 větších, než teoretická hodnota. Opět tedy modelujele $B(14,0.5)$. Graf \@ref(fig:znam-chart2) ukazuje toto binomické rozložení. Modře je opět vyznačena oblast zamítnutí $H_0$. Protože používáme oboustranný test, pak je oblast zamítnutí symetricky na obou strannách od očekávané hodnoty. 

```{r znam-chart2, fig.cap="Distribuce pozorování větších než teoretická hodnota za předpokladu H0. Příklad obousměrného testu."}
x <- 0:14
p <- 0.5
t <- sum(znamenka)
pmf <- dbinom(x, size = k, prob = p)
# *2, protože  máme oboustranný test
p_hodnota <- sum(pmf[x>=t])*2
alpha <- 0.05
kriticka_hodnota <- qbinom(c(alpha/2, 1-alpha/2), size = k, prob = p)
plot(x, pmf,
     xlab = "x",
     ylab = "PMF",
     col = "grey",
     type = "h", lwd = 15,
     xlim = c(0, k),
     main = paste0("p=", round(p_hodnota, 2))
)

lines(x[x<kriticka_hodnota[1]], pmf[x<kriticka_hodnota[1]], col = "#1f77b4", type = "h", lwd = 15)
lines(x[x>kriticka_hodnota[2]], pmf[x>kriticka_hodnota[2]], col = "#1f77b4", type = "h", lwd = 15)
abline(v = t, lty = 2)
axis(1, 0:k, 0:k)
legend("topright",
       legend = c(
         "B(14,0.5)",
         "Oblast zamítnutí",
         "Testovací statistika"),
       col = c("grey", "#1f77b4", "black"),
       lwd = c(5, 5, 1),
       lty = c(1,1, 2),
       cex = 0.7
)
```

Jak je vidět, pravděpodobnost, že bychom za předpokladu $H_0: \eta=5$ sledovali více než `r plusova_znamenka` hodnot větších než teoretická hodnota nebo `r k-plusova_znamenka` menších než teoretická hodnota je `r round(p_hodnota, 2)`. Nemůžeme tedy zamítnout $H_0$ ve prospěch $H_1$. V `R` je možné tento test provést pomocí funkce `binom.test`.

```{r}
# prvni priklad (H0: eta<=8, H1: eta > 8)
# binom.test(3, 14, alternative = "greater")
# druhy priklad (H0: eta=5, H1: eta != 5)
# binom.test(9, 14, alternative = "two.sided")
```

## Mann-Whitney U test
Tento typ testu se používá, pokud chceme porovnat medián dvou nezávislých výběrů. Narozdíl od t-testu nemusí být proměnné normálně rozděleny. 

Pětadvacet studentů angličtiny bylo na začátku školního roku náhodně rozděleno do dvou seminárních skupin. V první skupině probíhala výuka standardním způsobem a ve druhé skupině byla v průběhu roku aplikována nová metoda výuky angličtiny. Na konci školního roku absolvovali obě skupiny studentů jazykovou zkoušku TOEFL (skládající se čtyř částí: reading, listening, speaking a writing). Souhrnné výsledky obou skupin shrnuje následující tabulka:

|          | | | | | | | | | | | | | |
|----------|-|-|-|-|-|-|-|-|-|-|-|-|-|
|Standardní metoda výuky |96|65|67|72|63|55|56|64|84|80|52|51| |
|Nová metoda výuky |76|80|88|70|83|94|87|90|73|89|79|69|97|

Zajímá nás, zda jsou mezi oběma metodami rozdíly u standardizované jazykové zkoušky TOEFL? Tedy $H_0: \eta_1 = \eta_2$ a $H_1: \eta_1 \ne \eta_2$.

```{r}
standard <- c(96, 65, 67, 72, 63, 55, 56, 64, 84, 80, 52, 51)
experiment <- c(76, 80, 88, 70, 83, 94, 87, 90, 73, 89, 79, 69, 97)
eta_1 <- median(standard)
eta_2 <- median(experiment)
```

Medián v prvním výběru standardní výuky je `r eta_1`. Medián v druhém výběru experimentální výuky je `r eta_2`. Jako první vypočítáme pořadí všech hodnot, od nejmenšího po největší hodnotu a sečteme pořadí hodnot pro každou skupinu do $R_1$ a $R_2$.

```{r}
n1 <- length(standard)
n2 <- length(experiment)
r <- rank(c(standard, experiment))
R1 <- sum(r[1:n1])
R2 <- sum(r[(n1+1):(n1+n2)])
```

Součet pořadí hodnot ve standardní skupině je `r R1`. Součet pořadí hodnot v experimentální skupině je `r R2`. Nyní vypočítáme testovací statistiku $U$ pro oba výběry. $U_1 = R_1-\frac{n_1(n_1+1)}{2}$ a $U_2 = R_2-\frac{n_2(n_2+1)}{2}$.
```{r}
U1 <- R1 - (n1*(n1+1)/2)
U2 <- R2 - (n2*(n2+1)/2)
U <- min(U1, U2)

mu_U <- n1*n2/2
sigma_U <- sqrt((n1*n2*(n1+n2+1))/12)
z <- (U-mu_U) / sigma_U
```

Testovací statistika pro výběr standardní výuky je `r U1` a pro výběr experimentální výuky je `r U2`. Jako testovací statistiku $U$ vybereme menší z obou hodnot, tedy $U=min(U_1, U_2)$. V našem případě je tedy $U$ rovno `r U`. Protože testovací statistika nabývá normálního rozdělení, abyhcom ji mohli porovnat k očekávanému rozdělní za platnosti $H_0$, musíme vypočítat průměr a směrodatbou odchylku rozdělení této testovací statistiky. Průměr výběrového rozdělení testovací statistiku $U$ vypočítáme jako $\mu_U=\frac{n_1n_2}{2}$. V našem případě je tato hodnota rovna `r mu_U`. Směrodatná chyba odhadu $U$ se vypočítá jako $\sigma_U = \sqrt{\frac{n_1n_2(n_1+n_2+1)}{12}}$. Hodnotu kvantilu testovací statistiky vypočítáme jako $z=\frac{U-\mu_U}{\sigma_U}$.

```{r, fig.cap='Výběrové rozdělení U za předpokladu H0'}
x <- seq(10,150, length.out=1000)
pdf <- dnorm(x, mu_U, sigma_U)
alpha <- 0.05
kriticka_mez <- qnorm(c(alpha/2, 1-alpha/2), mean = mu_U, sigma_U)
p_hodnota <- pnorm(z) *2
# p_hodnota <- pnorm(U, mu_U, sigma_U) *2 # nebo take

plot(x, pdf, 
     type = "l", 
     lwd = 2,
     col = "grey",
     xlab = "U", ylab = "PDF")
abline(v = U, lty = 2)
lines(x[x<kriticka_mez[1]], pdf[x<kriticka_mez[1]], type = "h", col = "#1f77b4", lwd = 1)
lines(x[x>kriticka_mez[2]], pdf[x>kriticka_mez[2]], type = "h", col = "#1f77b4", lwd = 1)

legend("topright",
       legend = c(
         paste0(
           "N(", mu_U, ", ",
           round(sigma_U, 3), ")"
         ),
         "Testovací statistika"),
       col = c("grey", "black"),
       lwd = c(2, 1),
       lty = c(1,2),
       cex = 0.7
)
```

Pravděpodobnost, že bychom za předpokladu $H_0: \eta_1 = \eta_2$ sledovali testovací statistiku takovou nebo extrémnější je `r round(p_hodnota, 3)`, tedy pod hranicí zvolené $\alpha=0.05$. Zamítáme tedy $H_0$ ve prospěch $H_1$.

